{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f9f5e8",
   "metadata": {},
   "source": [
    "ссылка на гитхаб репозиторий\n",
    "\n",
    "https://github.com/theorcos239/async_ppo.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8b913",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Коротко о структуре\n",
    "\n",
    "model.py - файл, в котором хранится класс основной действующей модели: свёрточная нейронная сеть \n",
    "с двумя головами для actor и critic\n",
    "\n",
    "learner.py - файл, содержащий класс, реализующий PPO, с соответствующими методами по сбору роллаутов и обучению\n",
    "\n",
    "rollout_buffer.py - реализация класса роллаута\n",
    "\n",
    "worker_process.py - функция процесса асинхронного воркера для сбора роллаутов\n",
    "\n",
    "learner_process.py - процесс обучения центральной модели \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074df1bc",
   "metadata": {},
   "source": [
    "# Параметры эксперимента\n",
    "\n",
    "workers_count = 4\n",
    "\n",
    "rollout_size = 2048\n",
    "\n",
    "lr = 3e-4\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "n_epochs = 4\n",
    "                        \n",
    "gamma = 0.99 \n",
    "\n",
    "delta = 0.95\n",
    "\n",
    "clip_eps = 0.2\n",
    "                              \n",
    "entropy_coef = 0.01 \n",
    "\n",
    "value_coef = 0.5\n",
    "\n",
    "Обучение проходило в течение 3-5 часов на эксперимент до плато на графике reward(полное обучение). Требуемые графики(все 7) находятся в ppo_plots. В результатах только самое примечательное.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea5bf7",
   "metadata": {},
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e924229",
   "metadata": {},
   "source": [
    "На всех графиках время измеряется в минутах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8740fa",
   "metadata": {},
   "source": [
    "<img src=\"./ppo_plots/reward_vs_time.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2cfd50",
   "metadata": {},
   "source": [
    "На этом графике представлен также результат обучения синхронной версии. Видно, что синхронная модель обучается сильно медленне, в частности, из-за простоя критика. Синхронная версия обучалачь около 500 минут и только там вышла на плато (кусок графика обрезан, иначе бы асинхронные графики сжались и стали непонятными).\n",
    "\n",
    "В среднем модели с параматром frequency = 1 обучаются быстрее, потому что обновление весов чаще => меньше устаревающей информации. Поэтому модель тренируется на актульных данных.\n",
    "\n",
    "По аналогичной причине в среднем чем меньше max_queue_sizeб тем данные меньше застаиваются => опять лучше. Но это не всегда так, потому что набор параметров (10,10) показал себя довольно достойно, но это скорее выброс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dfa773",
   "metadata": {},
   "source": [
    "<img src=\"./ppo_plots/reward_vs_envsteps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace3545",
   "metadata": {},
   "source": [
    "Аналогичная история для графика reward от envsteps. Потому что env_teps очень сильно зависит от времени, а воркеров одно и тоже количество во всех экспериментах. Иногда, конечно, локальные сдвиги графиков по сравнению с предыдущим просиходят из-за простоев. Но в целом закономерность та же."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09743f1",
   "metadata": {},
   "source": [
    "<img src=\"./ppo_plots/updates_vs_time.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1c98",
   "metadata": {},
   "source": [
    "Выше тоже закономерный результат. Зависимость примерно линейная с момента, когда все процессы разогнались и стабилизировались. По такой же причине на графике env_steps от времени тоже линейный."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ab669",
   "metadata": {},
   "source": [
    "<img src=\"./ppo_plots/qsize_vs_time.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea35be",
   "metadata": {},
   "source": [
    "Из графика зависимости размера очереди от времени видно, что очередь во всех случаях обычно полна и редко изменяется на 1. Наверное, это связано с тем, что нейронная сеть всё таки не успевает обрабатывать всё, что приходит от воркеров. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727d53a",
   "metadata": {},
   "source": [
    "<img src=\"./ppo_plots/versiondiff_vs_time.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ea46f",
   "metadata": {},
   "source": [
    "Видно, что постепенно версия роллаутов догоняет версию центральной нейросети, а затем держится примерно на одном уровне. И отставание в итоге не очень большое. Поэтому данные не очень старые и алгоритм сходится."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
